{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b8a01f",
   "metadata": {},
   "source": [
    "# Phase 1: Downloading the Dataset\n",
    "\n",
    "The snippet of code below fetches records for all ATP Tennis matches within the past ten years (2015-2024), in CSV format (one file per year of matches). I have decided to utilise [JeffSackmann's tennis dataset](https://github.com/JeffSackmann/tennis_atp) since his recordings are very granular, even going as far to provide insight on stats such as FH winners and BP saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1190c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import date\n",
    "\n",
    "def download_historical_dataset(year_count=10):\n",
    "    for year in range(date.today().year - year_count, date.today().year):\n",
    "        response = requests.get(f\"https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_{year}.csv\")\n",
    "        if response.status_code == 200:\n",
    "            with open(f\"../data/atp_matches_{year}.csv\", \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Dataset for {year} all ATP matches downloaded successfully!\")\n",
    "        else:\n",
    "            print(f\"Failed to download dataset for {year} ATP matches. Status code: {response.status_code}\")\n",
    "\n",
    "os.makedirs(\"../data\", exist_ok=True)  # exist_ok=True avoids error if directory exists\n",
    "download_historical_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b0bdb",
   "metadata": {},
   "source": [
    "Note that as of writing, JeffSackmann's log of the 2025 ATP matches are not published (I anticipate this data will be available upon the end of the tennis calendar at December). Therefore I have also written some code to download the live tennis dataset by Kaggle, which are updated at a daily basis. (although this dataset has not been incorporated in to the pipeline as of yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "def download_live_dataset():\n",
    "    filepath = f\"../data/live_dataset_{date.today().isoformat()}.csv\"\n",
    "    try:\n",
    "        path = kagglehub.dataset_download(\"dissfya/atp-tennis-2000-2023daily-pull\", path=\"atp_tennis.csv\")\n",
    "        shutil.move(path, filepath)\n",
    "        print(\"Dataset downloaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading dataset: {e}\")\n",
    "\n",
    "#download_live_dataset() don't need to run this as the data is not used in the pipeline yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
